# üîê Network Malware Detection ‚Äî TrafficClassifier

Este projeto tem como objetivo aplicar um modelo supervisionado de aprendizado de m√°quina para detectar tr√°fego malicioso em redes, utilizando o algoritmo **Random Forest**. A abordagem envolve desde o pr√©-processamento dos dados at√© a avalia√ß√£o do modelo com m√©tricas robustas e curvas ROC.

## üìä Vis√£o Geral

O pipeline completo inclui:

- Carregamento eficiente dos dados com infer√™ncia de tipos
- Armazenamento em formato `.parquet` para otimiza√ß√£o de desempenho
- An√°lise explorat√≥ria e tratamento de dados ausentes com `IterativeImputer`
- Engenharia de features para extrair padr√µes temporais e de tr√°fego
- Codifica√ß√£o de vari√°veis categ√≥ricas e filtragem de r√≥tulos pouco representativos
- Redu√ß√£o de dimensionalidade com an√°lise de correla√ß√£o
- Treinamento e avalia√ß√£o de modelo com m√©tricas e curvas ROC

## üß† Modelo Utilizado

O classificador principal √© o **RandomForestClassifier**, configurado com os seguintes hiperpar√¢metros:

- `n_estimators=200`
- `max_depth=30`
- `min_samples_split=10`
- `min_samples_leaf=5`
- `max_features='sqrt'`
- `class_weight='balanced'`

## Dicas

Em caso de algum erro no processo rode:

`pip install -r requirements.txt`


## Executando o notebook

A principio todo notebook esta automatizado, des do dowload dos arquivos at√© o resultado final.

## Fpipeline

O arquivo Fpipeline.py cont√©m a implementa√ß√£o da classe TrafficClassifier, respons√°vel por executar todas as etapas do pipeline de classifica√ß√£o de tr√°fego de rede malicioso. Ele foi projetado para ser modular, eficiente e facilmente reutiliz√°vel em diferentes conjuntos de dados com estrutura semelhante.

## Principais Funcionalidades

1. Pr√©-processamento de Dados

    Convers√£o de timestamps e limpeza de r√≥tulos (label)

    Substitui√ß√£o de r√≥tulos gen√©ricos por r√≥tulos detalhados

    Remo√ß√£o de colunas irrelevantes e registros incompletos

    Codifica√ß√£o de protocolos (tcp, udp) e categoriza√ß√£o de portas

    Cria√ß√£o de vari√°veis derivadas como byte_ratio, pkts_per_sec, burst_density, entre outras

2. Tratamento de Dados

    Imputa√ß√£o de valores ausentes com IterativeImputer (baseado em modelos estat√≠sticos)

    Limita√ß√£o de outliers com base em percentis (default: 95%)

3. Engenharia de Features

    C√°lculo de correla√ß√£o entre vari√°veis num√©ricas

    Remo√ß√£o de atributos altamente correlacionados para evitar redund√¢ncia e overfitting

    Codifica√ß√£o one-hot das categorias de portas de origem e destino

4. Treinamento e Avalia√ß√£o

    Separa√ß√£o dos dados em treino e teste com estratifica√ß√£o

    Treinamento do modelo RandomForestClassifier com hiperpar√¢metros ajustados

    Avalia√ß√£o com matriz de confus√£o e relat√≥rio de classifica√ß√£o

    Plotagem de curvas ROC para problemas bin√°rios ou multiclasse

## ‚ñ∂Ô∏è Exemplo de Execu√ß√£o

```python
import pandas as pd
from Fpipeline import TrafficClassifier

# Carrega o dataset (ajuste o caminho conforme necess√°rio)
df = pd.read_parquet("raw/dataset.parquet")

# Instancia o classificador
classifier = TrafficClassifier()

# Executa o pipeline completo
classifier.run_pipeline(df)

```

## ‚öôÔ∏è Exemplo com Par√¢metros Personalizados

```python

from Fpipeline import TrafficClassifier
import pandas as pd

# Carrega o dataset
df = pd.read_parquet("raw/dataset.parquet")

# Instancia o classificador com par√¢metros customizados
classifier = TrafficClassifier(
    min_label_count=50,           # Reduz o m√≠nimo de amostras por classe
    test_size=0.3,                # Usa 30% dos dados para teste
    random_state=123,            # Altera a semente para reprodutibilidade
    n_estimators=300,            # Aumenta o n√∫mero de √°rvores
    max_depth=40,                # Permite √°rvores mais profundas
    min_samples_split=5,         # Divide com menos amostras
    min_samples_leaf=2,          # Permite folhas menores
    max_features='log2',         # Muda a estrat√©gia de sele√ß√£o de features
    class_weight=None            # Desativa balanceamento autom√°tico
)

# Executa o pipeline completo
classifier.run_pipeline(df)
```